{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 에이전트 대화 시뮬레이션 - 고객 응대 시나리오\n",
    "\n",
    "고객 지원 어시스턴트의 경우, 챗봇의 성능을 평가하는 것이 어려울 수 있습니다. 코드 변경마다 수동으로 테스트 하는것은 시간이 많이 소요됩니다. \n",
    "평가 과정을 더 쉽고 재현 가능하게 만드는 한가지 방법은 사용자 상호작용을 시뮬레이션 하는것 입니다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "LangGraph-Agent-Simulation\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langgraph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlangsmith\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m langsmith \n\u001b[1;32m     14\u001b[0m langsmith(project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLangGraph-Agent-Simulation\u001b[39m\u001b[38;5;124m\"\u001b[39m, set_enable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m add_messages\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Annotated \n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TypedDict \n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langgraph'"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv \n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root directory (parent of src) to sys.path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from config.langsmith import langsmith \n",
    "\n",
    "langsmith(project_name=\"LangGraph-Agent-Simulation\", set_enable=True)\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated \n",
    "from typing_extensions import TypedDict \n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 상담사, 고객 역할 정의 \n",
    "\n",
    "### 상담사 역할 정의 \n",
    "* 시뮬레이션에서 상담사 역할을 하는 챗봇 정의 \n",
    "\n",
    "**참고**\n",
    "* `call_chatbot` 내의 구현은 설정 가능하며, 내부에서 사용한 모델을 Agent로 변경하는 것도 가능합니다. \n",
    "* `call_chatbot` 은 사용자로부터 메시지를 입력으로 받아, 고객을 상담하는 역할을 부여하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List \n",
    "from langchain_google_vertexai import ChatVertexAI \n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagePlaceholder \n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage \n",
    "from langchain_core.output_parsers import StrOutputParser \n",
    "\n",
    "def call_chatbot(messages: List[BaseMessage]) -> dict:\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a customer support agent for an airline. Answer in Korean.\"\n",
    "            ),\n",
    "            MessagePlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "    model = ChatVertexAI(\n",
    "        model_name=\"gemini-2.0-flash-001\",\n",
    "        temperature=0.0,\n",
    "        max_tokens=4096,\n",
    "    )\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "    return chain.invoke({\"messages\": messages})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 고객 역할 정의 (simulated user)\n",
    "\n",
    "시뮬레이션 된 고객의 역할을 정의합니다. 고객 지원 시나리오에서의 대화를 시뮬레이션 합니다.   \n",
    "시스템 프롬프트는 고객과 고객 지원 담당자간의 상호작용을 설정하며, 사용자 지시사항을 통해 시나리오의 세부 사항을 제공합니다.  \n",
    "이 구성은 특정 사용자 요구 (예 : 환불 요청) 에 대한 모델의 반응을 시뮬레이션 하는데 사용됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder \n",
    "\n",
    "def create_scenario(name: str, instructions: str):\n",
    "    # 시스템 프롬프트 정의 : 필요에 따라 변경 \n",
    "    systemp_prompt_template = \"\"\" \n",
    "    You are a customer of  an airline company. You are interacting with a user who is a customer support person. \n",
    "\n",
    "    Your name is {name}.\n",
    "\n",
    "    # Instructions : \n",
    "    {instructions}\n",
    "\n",
    "    [Important]\n",
    "    - When you are finished with the conversation, respond with a single word 'FINISHED'.\n",
    "    - You must speak in Korean.\n",
    "    \"\"\"\n",
    "\n",
    "    # 대화 메시지와 시스템 프롬프트를 결합하여 채팅 프롬프트 템플릿을 생성합니다. \n",
    "    # 사용자 프롬프트 정의 : 시나리오 설명 \n",
    "    user_prompt_template = \"\"\" \n",
    "    {name} is a {instructions}. \n",
    "    \"\"\"\n",
    "    # 프롬프트 템플릿 생성 \n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", systemp_prompt_template),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "    prompt = prompt.partial(name=name, instructions=instructions)\n",
    "    return prompt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가상 시나리오 생성 (고객입장)\n",
    "# 사용자 지시사항 설정 \n",
    "instructions = \"\"\" \n",
    "    You are trying to get a refund for the trip you took to Jeju Island. \n",
    "    You want them to give you ALL the money back. \n",
    "    This trip happened last year\n",
    "\"\"\"\n",
    "\n",
    "# 사용자 이름 정의 \n",
    "name = \"Teddy\"\n",
    "\n",
    "create_scenario(name, instructions).pretty_print() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI \n",
    "\n",
    "# 챗봇 모델 초기화\n",
    "model = ChatVertexAI(\n",
    "    model_name=\"gemini-2.0-flash-001\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=4096,\n",
    ")\n",
    "\n",
    "# 시뮬레이션된 사용자 대화 생성 \n",
    "simulated_user = create_scenario(name, instructions) | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulated_user 를 호출하여 시뮬레이션 된 사용자에게 메시지를 전달. \n",
    "\n",
    "# 시뮬레이션된 사용자에게 메시지를 전달 \n",
    "messages = [HumanMessage(content=\"안녕하세요? 무엇을 도와드릴까요?\")]\n",
    "\n",
    "simulated_user.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 에이전트 시뮬레이션 정의하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "노드 정의\n",
    "* 메시지 목록을 입력으로 받아 상태에 추가할 메시지 목록을 반환해야 합니다. \n",
    "챗봇과 시뮬레이션된 사용자를 둘러싼 것 래퍼들입니다. \n",
    "\"\"\"\n",
    "\n",
    "from langchain_core.messages import AIMessage \n",
    "\n",
    "# 상담사 역할\n",
    "def ai_assistant_node(messages):\n",
    "    # 상담사 응답 호출\n",
    "    ai_response = call_chatbot(messages)\n",
    "    \n",
    "    # AI 상담사의 응답을 반환 \n",
    "    return {\"messages\": [(\"assistant\", ai_response)]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 상담사 역할 노드 호출 \n",
    "ai_assistant_node(\n",
    "    [\n",
    "        (\"user\", \"안녕하세요?\"),\n",
    "        (\"assistant\", \"안녕하세요! 무엇을 도와드릴까요?\"),\n",
    "        (\"user\", \"환불하고싶어요.\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _swap_roles(messages):\n",
    "    # 메세지의 역할을 교환: 시뮬레이션 사용자 단계에서 메시지 타입을 AI -> Human, Human -> AI로 교환 \n",
    "    new_messages = []\n",
    "    for m in messages:\n",
    "        if ininstance(m, AIMessage):\n",
    "            # AIMessage 인 경우 HumanMessage로 변환 \n",
    "            new_messages.append(HumanMessage(content=m.content))\n",
    "        else:\n",
    "            # HumanMessage 인 경우 AIMessage로 변환 \n",
    "            new_messages.append(AIMessage(content=m.content))\n",
    "    return new_messages\n",
    "\n",
    "# 상담사 역할 노드 정의 \n",
    "def ai_assistant_node(state:State):\n",
    "    # 상담사 응답 반환\n",
    "    ai_response = call_chatbot(state[\"messages\"])\n",
    "    # AI 상담사 응답을 반환 \n",
    "    return {\"messages\": [(\"assistant\", ai_response)]}\n",
    "\n",
    "# 시뮬레이션된 사용자 노드 정의\n",
    "def simulated_user_node(state:State):\n",
    "    # 메시지 타입을 교환 : AI -> Human, Human -> AI\n",
    "    new_messages = _swap_roles(state[\"messages\"])\n",
    "    # 시뮬레이션된 사용자를 호출\n",
    "    response = simulated_user.invoke({\"messages\":new_messages})\n",
    "    return {\"messages\": [(\"user\", response)]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 엣지 정의 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "엣지 정의 \n",
    "* 시뮬레이션된 사용자가 작업을 마친 후 발생하며, 두가지 결과 중 하나로 이어져야함. \n",
    "-> 고객 지원 봇을 호출하여 계속 진행 (\"continue\")\n",
    "-> 대화를 마치고 종료 (\"end\")\n",
    "\n",
    "* 대화 종료 로직\n",
    "-> 인간 챗봇이 FINISHED 라는 단어를 반환하면 대화가 종료\n",
    "-> 대화가 6개 메시지를 초과하는 경우 대화가 종료\n",
    "\"\"\"\n",
    "\n",
    "# 대화 종료 엣지 정의 \n",
    "def should_continue(state:State):\n",
    "    # 대화가 6개 메시지를 초과하는 경우 대화가 종료\n",
    "    if len(state[\"messages\"]) > 6:\n",
    "        return \"end\"\n",
    "    # 인간 챗봇이 FINISHED 라는 단어를 반환하면 대화가 종료\n",
    "    elif state[\"messages\"][-1].content == \"FINISHED\":\n",
    "        return \"end\"\n",
    "    # 위 조건에 해당되지 않으면 대화가 계속됨\n",
    "    else:\n",
    "        return \"continue\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그래프 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "시뮬레이션을 설정하는 그래프 정의\n",
    "\"\"\"\n",
    "\n",
    "from langgraph.graph import END, StateGraph \n",
    "\n",
    "# StateGraph 인스턴스 생성\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "#노드 정의\n",
    "graph_builder.add_node(\"simulated_user\", simulated_user_node)\n",
    "graph_builder.add_node(\"ai_assistant\", ai_assistant_node)\n",
    "\n",
    "# 엣지 정의 (챗봇 -> 시뮬레이션된 사용자)\n",
    "graph_builder.add_edge(\"ai_assistant\", \"simulated_user\")\n",
    "\n",
    "# 조건부 엣지 정의\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"simulated_user\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"end\" : END,\n",
    "        \"continue\" : \"ai_assistant\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# 시작점 설정 \n",
    "graph_builder.set_entry_point(\"ai_assistant\")\n",
    "\n",
    "# 그래프 컴파일\n",
    "simulation = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(simulation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
